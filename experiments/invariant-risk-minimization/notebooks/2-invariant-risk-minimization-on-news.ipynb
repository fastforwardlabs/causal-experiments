{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IRM news popularity\n",
    "\n",
    "IRM is a compelling idea, bringing invariant causal prediction further into the world of machine learning. However, the results demonstrated in the paper are produced on datasets constructed for the purpose. Let's try it on a real problem.\n",
    "\n",
    "To use IRM, we need to be able to construct datasets from different environments. The paper seems not to be very explicit about it, but I think the environments need the same thing as in the case of the Peters et al Invariant Causal Prediction paper - they should be constructed by \"interventions\" (really here just selection) on something that is not a direct cause of the outcome.\n",
    "\n",
    "This [online news popularity](https://archive.ics.uci.edu/ml/datasets/Online+News+Popularity) dataset seems to follow that form. There are many engineered features (typical for ML), which are all potential direct causes of article popularity (measured by number of shares). Also recorded are the number of days that have passed since the article was released (at time of collection). We'd expect, after an initial period, that this does not effect the number of shares, and as such, we can construct environments by splitting on it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.autograd import grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/OnlineNewsPopularity/OnlineNewsPopularity.csv')\n",
    "df.columns = df.columns.map(str.strip) # remove leading spaces from column names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into environments\n",
    "\n",
    "We'll split on the number of days since release, which covers almost two years. We can experiment with how many environments we create."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min timedelta:  8.0\n",
      "max timedelta:  731.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x133c48780>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('min timedelta: ', df.timedelta.min())\n",
    "print('max timedelta: ', df.timedelta.max())\n",
    "df.timedelta.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment_1_df = df[df.timedelta < 180]\n",
    "environment_2_df = df[(df.timedelta >= 180) & (df.timedelta < 360)]\n",
    "environment_3_df = df[(df.timedelta >= 360) & (df.timedelta < 540)]\n",
    "environment_4_df = df[(df.timedelta >= 540)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are our environments about equally sized?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10866, 9993, 8690, 10095]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in map(len, [environment_1_df, environment_2_df, environment_3_df, environment_4_df])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Close enough.\n",
    "\n",
    "## IRM on two environments\n",
    "\n",
    "We'll first perform IRM on two environments to arrive an invariant representation. We'll then test the performance of the IRM representation vs a non-IRM learned version on the two holdout environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_tensors(df):\n",
    "    features = torch.tensor(\n",
    "        df.drop(['url','timedelta','shares'],\n",
    "                axis='columns')\n",
    "          .to_numpy()\n",
    "    ).double()\n",
    "    \n",
    "    target = torch.tensor(\n",
    "        df['shares'].to_numpy()\n",
    "    ).unsqueeze(1).double()\n",
    "    \n",
    "    return (features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_1_tensors = df_to_tensors(environment_1_df)\n",
    "env_2_tensors = df_to_tensors(environment_2_df)\n",
    "env_3_tensors = df_to_tensors(environment_3_df)\n",
    "env_4_tensors = df_to_tensors(environment_4_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = env_1_tensors[0].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_environments = [env_1_tensors, env_2_tensors]\n",
    "holdout_environments = [env_3_tensors, env_4_tensors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into two random mini-batches of size b (random happens in the iteration)\n",
    "# an unbiased estimate of the squared gradient norm\n",
    "\n",
    "def compute_penalty(losses, dummy_w):\n",
    "    g1 = grad(losses[0::2].mean(), dummy_w, create_graph=True)[0]\n",
    "    g2 = grad(losses[1::2].mean(), dummy_w, create_graph=True)[0]\n",
    "    return (g1 * g2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi = torch.nn.Parameter(torch.ones(n_features, 1).double())\n",
    "dummy_w = torch.nn.Parameter(torch.Tensor([1.0])).double() # a dummy predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.Adam([phi], lr=1e-3)\n",
    "mse = torch.nn.MSELoss(reduction=\"none\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could probably speed up training by scaling (min-max or z-score) the input features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error:  2948864251254.466\n",
      "iteration:  0\n",
      "phi:  tensor([0.9990, 0.9990, 0.9990, 0.9990, 0.9990, 0.9990, 0.9990, 0.9990, 0.9990,\n",
      "        0.9990, 0.9990, 0.9990, 0.9990, 0.9990, 0.9990, 0.9990, 0.9990, 1.0010,\n",
      "        0.9990, 0.9990, 0.9990, 0.9990, 0.9990, 0.9990, 0.9990, 0.9990, 0.9990,\n",
      "        0.9990, 0.9990, 0.9990, 0.9990, 0.9990, 0.9990, 0.9990, 0.9990, 0.9990,\n",
      "        0.9990, 0.9990, 0.9990, 0.9990, 0.9990, 0.9990, 0.9990, 0.9990, 0.9990,\n",
      "        0.9990, 0.9990, 0.9990, 0.9990, 0.9990, 0.9990, 1.0010, 1.0010, 1.0010,\n",
      "        0.9990, 0.9990, 0.9990, 0.9990], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "error:  612255738908.9043\n",
      "error:  228216353334.26666\n",
      "error:  107815745656.4092\n",
      "error:  56882808376.14217\n",
      "error:  31788232439.29389\n",
      "error:  18342502605.415916\n",
      "error:  10785680851.320368\n",
      "error:  6420548015.014734\n",
      "error:  3859962728.7640095\n",
      "error:  2345833811.3979073\n",
      "iteration:  10000\n",
      "phi:  tensor([0.0298, 0.0298, 0.0299, 0.0299, 0.0298, 0.0303, 0.0299, 0.0307, 0.0302,\n",
      "        0.0298, 0.0300, 0.0302, 0.0295, 0.0294, 0.0300, 0.0298, 0.0289, 1.9702,\n",
      "        0.0303, 0.0301, 0.0292, 0.0298, 0.0299, 0.0300, 0.0304, 0.0302, 0.0302,\n",
      "        0.0301, 0.0302, 0.0301, 0.0298, 0.0297, 0.0295, 0.0296, 0.0301, 0.0303,\n",
      "        0.0302, 0.0297, 0.0297, 0.0290, 0.0308, 0.0297, 0.0299, 0.0299, 0.0298,\n",
      "        0.0298, 0.0298, 0.0297, 0.0298, 0.0299, 0.0298, 1.9701, 1.9702, 1.9701,\n",
      "        0.0302, 0.0309, 0.0297, 0.0303], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "error:  1447579370.7891812\n",
      "error:  914745800.2202702\n",
      "error:  599556489.2034334\n",
      "error:  414104387.36479867\n",
      "error:  305876904.76574516\n",
      "error:  243454368.05334902\n",
      "error:  208044422.29273066\n",
      "error:  188426567.5262074\n",
      "error:  177923636.57365137\n",
      "error:  172580191.0152077\n",
      "iteration:  20000\n",
      "phi:  tensor([3.9233e-03, 3.8173e-03, 4.0680e-03, 3.9731e-03, 3.9099e-03, 4.9057e-03,\n",
      "        3.9741e-03, 5.5920e-03, 4.6019e-03, 3.7511e-03, 4.1937e-03, 4.5963e-03,\n",
      "        3.2855e-03, 3.0837e-03, 4.2349e-03, 3.8089e-03, 1.9921e-03, 1.9962e+00,\n",
      "        4.7719e-03, 4.5349e-03, 2.7784e-03, 3.8652e-03, 3.9599e-03, 4.3258e-03,\n",
      "        4.9457e-03, 4.6802e-03, 4.4453e-03, 4.4191e-03, 4.5678e-03, 4.3308e-03,\n",
      "        3.9150e-03, 3.7254e-03, 3.2858e-03, 3.4737e-03, 4.4690e-03, 4.8964e-03,\n",
      "        4.6924e-03, 3.5916e-03, 3.7026e-03, 2.2525e-03, 5.8969e-03, 3.7043e-03,\n",
      "        4.0098e-03, 4.0073e-03, 3.8885e-03, 3.8990e-03, 3.7839e-03, 3.7313e-03,\n",
      "        3.9281e-03, 3.9776e-03, 3.8920e-03, 1.9960e+00, 1.9961e+00, 1.9959e+00,\n",
      "        4.5408e-03, 6.0224e-03, 3.7129e-03, 4.8161e-03], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "error:  170067206.20793653\n",
      "error:  169026874.30437025\n",
      "error:  168680578.69167683\n",
      "error:  168603083.65247232\n",
      "error:  168595602.95244122\n",
      "error:  168597035.0637632\n",
      "error:  168601292.73927984\n",
      "error:  168614164.1897269\n",
      "error:  168655272.847878\n",
      "error:  168795316.50362507\n",
      "iteration:  30000\n",
      "phi:  tensor([ 2.5077e-03,  2.3626e-03,  2.9198e-03,  2.7861e-03,  2.7207e-03,\n",
      "         3.6661e-03,  3.3779e-03,  5.4210e-03,  2.8727e-03,  2.6264e-03,\n",
      "         3.0915e-03,  2.6365e-03,  1.7255e-03,  2.9588e-03,  6.0757e-03,\n",
      "         3.0315e-03, -4.3575e-04,  1.9975e+00,  4.8591e-03,  4.6626e-03,\n",
      "         2.1304e-03,  2.6096e-03,  2.5449e-03,  2.9567e-03,  4.2908e-03,\n",
      "         3.5902e-03,  5.6599e-03,  7.8399e-03,  7.5630e-03,  2.7006e-03,\n",
      "         2.2474e-03,  2.4437e-03,  2.8229e-03,  2.8643e-03,  2.1173e-03,\n",
      "         3.1892e-03,  2.6775e-03,  3.2232e-03,  2.4089e-03,  6.3888e-04,\n",
      "         4.3246e-03,  2.5256e-03,  2.8917e-03,  3.3685e-03,  2.9870e-03,\n",
      "         2.5364e-03,  2.7986e-03,  2.2790e-03,  2.8714e-03,  3.0318e-03,\n",
      "         2.8210e-03,  1.9972e+00,  1.9975e+00,  1.9970e+00,  2.8233e-03,\n",
      "         4.2521e-03,  2.5161e-03,  3.0264e-03], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "error:  169234965.021179\n",
      "error:  170099594.6025024\n",
      "error:  170702731.40525892\n",
      "error:  170905470.8285902\n",
      "error:  171095165.9268715\n",
      "error:  172132268.0937523\n",
      "error:  175666421.64358005\n",
      "error:  175401992.59286407\n",
      "error:  176186392.79776338\n",
      "error:  175217985.0172087\n",
      "iteration:  40000\n",
      "phi:  tensor([ 8.7587e-03,  4.2285e-02, -1.3652e-02, -8.0116e-03, -1.0211e-02,\n",
      "         6.6911e-02,  7.1504e-03,  4.2009e-02,  7.2573e-02,  3.4268e-03,\n",
      "         1.1393e-02,  4.3805e-02, -9.0987e-03, -4.8903e-02, -1.1039e-01,\n",
      "         4.2104e-02, -3.7182e-02,  2.0069e+00, -2.0340e-02, -2.7266e-02,\n",
      "        -2.4586e-03,  9.6154e-04,  3.1526e-03,  1.4332e-02,  7.0957e-03,\n",
      "         1.7411e-02,  7.6252e-02, -4.4361e-03,  1.0362e-02,  1.3964e-02,\n",
      "         2.4290e-02,  2.6236e-02, -7.1839e-02, -4.5644e-02,  8.5308e-02,\n",
      "         5.9639e-02,  7.1913e-02, -2.0724e-02, -1.2022e-02, -4.8946e-02,\n",
      "         6.5924e-02,  9.7915e-03,  1.3973e-02, -1.2437e-02, -4.7841e-04,\n",
      "         2.9093e-02, -3.8171e-03,  2.1340e-02,  7.4166e-03, -2.1912e-03,\n",
      "         5.2435e-03,  1.9789e+00,  1.9839e+00,  1.9840e+00,  6.0603e-02,\n",
      "         1.5336e-01, -1.6435e-02,  8.0665e-02], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "error:  174327727.24405468\n",
      "error:  175209649.79550308\n",
      "error:  174517266.27997792\n",
      "error:  174952658.56568387\n",
      "error:  175758045.5918207\n"
     ]
    }
   ],
   "source": [
    "for iteration in range(50000):\n",
    "    error = 0\n",
    "    penalty = 0\n",
    "    for x_e, y_e in train_environments:\n",
    "        # here we permute data so that we get random minibatches when we compute the penalty.\n",
    "        # this gives us an unbiased estimate for the squared gradient norm.\n",
    "        p = torch.randperm(len(x_e))\n",
    "        error_e = mse(x_e[p] @ phi * dummy_w, y_e[p])\n",
    "        penalty += compute_penalty(error_e, dummy_w)\n",
    "        error += error_e.mean()\n",
    "        \n",
    "    opt.zero_grad()\n",
    "    (1e-5 * error + penalty).backward()\n",
    "    opt.step()\n",
    "    \n",
    "    if iteration % 1000 == 0:\n",
    "        print('error: ', error.item())\n",
    "    if iteration % 10000 == 0:\n",
    "        print('iteration: ', iteration)\n",
    "        print('phi: ', phi.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_env_1 = (env_1_tensors[0] @ phi).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(pd.DataFrame(\n",
    "    {'predictions': pred_env_1.tolist(),\n",
    "     'truth': env_1_tensors[1].squeeze().tolist()})\n",
    " .plot(x='truth', y='predictions',\n",
    "       kind='scatter',\n",
    "       alpha=0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result\n",
    "\n",
    "Clearly, we can't fit this dataset well with linear regression. In fact, the results are pretty poor. Fortunately, IRM works in nonlinear settings, but this requires some more work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(len(df), len(df[df.shares < 1500])) # -> 1500 shares is approximately half the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
